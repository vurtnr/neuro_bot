mod modules;
use modules::emotion::EmotionManager;
use modules::state::StateManager;

use r2r;
use r2r::robot_interfaces::msg::AudioSpeech;
use r2r::robot_interfaces::srv::AskLLM;
use r2r::std_msgs::msg::String as StringMsg;

use futures::StreamExt;
use std::sync::Arc; // [ä¿®å¤] åªå¼•å…¥ Arcï¼Œä¸éœ€è¦ Mutex
use std::time::Duration;
use tokio::time;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    println!("ğŸ§  Brain Core (Modular Architecture) Starting...");

    let ctx = r2r::Context::create()?;
    let mut node = r2r::Node::create(ctx, "brain_core", "")?;

    // å®ä¾‹åŒ–æ¨¡å—
    let emotion_manager = EmotionManager::new(&mut node)?;
    let state_manager = StateManager::new(&mut node)?;

    let tts_publisher =
        node.create_publisher::<StringMsg>("/audio/tts_play", r2r::QosProfile::default())?;

    // [å…³é”®ä¿®å¤] ä½¿ç”¨ Arc::new åŒ…è£¹ Client
    // è¿™æ · llm_client çš„ç±»å‹å˜æˆäº† Arc<Client<...>>ï¼Œå®ƒæ˜¯å¯ä»¥è¢« clone çš„
    let llm_client = Arc::new(
        node.create_client::<AskLLM::Service>("/brain/ask_llm", r2r::QosProfile::default())?,
    );

    let mut speech_sub =
        node.subscribe::<AudioSpeech>("/audio/speech", r2r::QosProfile::default())?;

    println!("ğŸ”— Waiting for dependencies...");

    tokio::task::spawn(async move {
        println!("âœ… Brain Logic Loop Started.");

        while let Some(msg) = speech_sub.next().await {
            if !msg.is_final {
                continue;
            }

            println!("ğŸ‘‚ Input: \"{}\"", msg.text);

            // çŠ¶æ€ä¸€ï¼šæ€è€ƒ
            state_manager.set_thinking();
            emotion_manager.set_thinking();

            // [ä¿®å¤å] è¿™é‡Œ clone çš„æ˜¯ Arc æŒ‡é’ˆï¼Œè€Œä¸æ˜¯ Client æœ¬èº«ï¼Œè¿™æ˜¯åˆæ³•çš„ä¸”å¼€é”€æå°
            let client = llm_client.clone();

            let mut s_mgr = state_manager.clone();
            let mut e_mgr = emotion_manager.clone();
            let tts_pub = tts_publisher.clone();
            let question = msg.text.clone();

            tokio::spawn(async move {
                let request = AskLLM::Request { question };

                println!("ğŸ¤” Requesting LLM...");
                // client æ˜¯ Arc<Client>ï¼Œå®ƒä¼šè‡ªåŠ¨è§£å¼•ç”¨è°ƒç”¨ request
                match client.request(&request).expect("Client fail").await {
                    Ok(response) => {
                        if response.success {
                            println!("ğŸ’¡ Answer: \"{}\"", response.answer);

                            // çŠ¶æ€äºŒï¼šè¯´è¯
                            s_mgr.set_speaking();
                            e_mgr.set_happy();

                            let tts_msg = StringMsg {
                                data: response.answer.clone(),
                            };
                            if let Err(e) = tts_pub.publish(&tts_msg) {
                                eprintln!("âŒ TTS Publish Error: {}", e);
                            }

                            // ä¼°ç®—è¯´è¯æ—¶é—´
                            let duration_secs =
                                std::cmp::max(2, (response.answer.chars().count() / 5) as u64);
                            time::sleep(Duration::from_secs(duration_secs)).await;
                        } else {
                            println!("âŒ LLM Refused: {}", response.answer);
                        }
                    }
                    Err(e) => {
                        println!("ğŸ”¥ LLM Service Call Failed: {}", e);
                    }
                }

                // çŠ¶æ€ä¸‰ï¼šå½’ä½
                println!("ğŸ’¤ Returning to Idle");
                s_mgr.set_idle();
                e_mgr.set_neutral();
            });
        }
    });

    loop {
        node.spin_once(Duration::from_millis(100));
    }
}
