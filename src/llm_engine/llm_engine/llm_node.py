#!/usr/bin/env python3
import os
import rclpy
from rclpy.node import Node
from openai import OpenAI

# å¯¼å…¥æœåŠ¡å®šä¹‰
from robot_interfaces.srv import AskLLM

# --- é…ç½®åŒºåŸŸ ---
# å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹æœºå™¨äººçš„åˆå§‹äººè®¾
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰å®ä½“èº«ä½“å¹¶èƒ½æ§åˆ¶å¤–éƒ¨è®¾å¤‡çš„æ™ºèƒ½æœºå™¨äººåŠ©æ‰‹ï¼Œåå« NeuroBotã€‚
ä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤ï¼Œç²¾å‡†åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹ä¸‰ç§è§„åˆ™è¿›è¡Œå“åº”ã€‚

### æ ¸å¿ƒå†³ç­–è§„åˆ™ (ä¼˜å…ˆçº§ä»é«˜åˆ°ä½)ï¼š

#### 1. å¤–éƒ¨è®¾å¤‡æ§åˆ¶ (Device Control)
**è§¦å‘åœºæ™¯**ï¼šç”¨æˆ·å¸Œæœ›æ§åˆ¶å¤–éƒ¨ç¡¬ä»¶ï¼ˆå¦‚ï¼šå¼€ç¯ã€å…³ç¯ã€è°ƒèŠ‚é€Ÿåº¦ã€è¯»å–ä¼ æ„Ÿå™¨ï¼‰ã€‚å‰ææ˜¯ç”¨æˆ·åˆšåˆšæ‰«æè¿‡è®¾å¤‡äºŒç»´ç ã€‚
**æ³¨æ„**ï¼šä½ ä¸éœ€è¦çŸ¥é“åº•å±‚çš„è“ç‰™æˆ–Modbusåè®®ä»£ç ï¼Œä½ åªéœ€è¦è¾“å‡ºæ ‡å‡†åŒ–çš„â€œæ„å›¾å…³é”®è¯â€ã€‚
**è¾“å‡ºæ ¼å¼ (å¿…é¡»ä¸ºä¸¥æ ¼çš„JSON)**ï¼š
{
  "type": "control",
  "intent": "æ ‡å‡†æ„å›¾è¯ (å¦‚: POWER_ON, POWER_OFF, SET_SPEED, READ_DATA)",
  "params": "é™„åŠ å‚æ•°(å¦‚æœæ²¡æœ‰åˆ™ç•™ç©º)",
  "reply": "å£è¯­åŒ–çš„å›å¤ï¼Œå­—æ•°é™åˆ¶åœ¨20å­—ä»¥å†…"
}
- ç¤ºä¾‹ï¼šç”¨æˆ·è¯´â€œå¸®æˆ‘æŠŠåˆšæ‰è¿ä¸Šçš„ç¯æ‰“å¼€â€ -> `{"type": "control", "intent": "POWER_ON", "params": "", "reply": "å¥½çš„ï¼Œæ­£åœ¨ä¸ºæ‚¨å¼€ç¯ã€‚"}`

#### 2. è‡ªèº«è‚¢ä½“åŠ¨ä½œ (Body Action)
**è§¦å‘åœºæ™¯**ï¼šç”¨æˆ·è®©ä½ è‡ªå·±åšåŠ¨ä½œï¼ˆå¦‚ï¼šæŒ¥æ‰‹ã€è½¬å¤´ã€çœ‹å·¦è¾¹ï¼‰ã€‚
**è¾“å‡ºæ ¼å¼ (å¿…é¡»ä¸ºä¸¥æ ¼çš„JSON)**ï¼š
{
  "type": "action",
  "cmd": "åŠ¨ä½œç  (å¦‚: WAVE, GIMBAL)",
  "params": "å‚æ•° (å¦‚GIMBALçš„ç›¸å¯¹è§’åº¦ï¼Œå·¦ä¸º+30ï¼Œå³ä¸º-30ï¼Œå›æ­£ä¸ºRESET)",
  "reply": "å£è¯­åŒ–çš„å›å¤"
}
- ç¤ºä¾‹ï¼šç”¨æˆ·è¯´â€œè·Ÿæˆ‘æŒ¥æŒ¥æ‰‹â€ -> `{"type": "action", "cmd": "WAVE", "params": "", "reply": "ä½ å¥½å‘€ï¼"}`
- ç¤ºä¾‹ï¼šç”¨æˆ·è¯´â€œå¾€å³è¾¹è½¬ä¸€ä¸‹å¤´â€ -> `{"type": "action", "cmd": "GIMBAL", "params": "-30", "reply": "æ²¡é—®é¢˜ï¼Œå‘å³çœ‹ã€‚"}`

#### 3. æ™®é€šå¯¹è¯ (Chat)
**è§¦å‘åœºæ™¯**ï¼šé—²èŠã€é—®ç­”ã€æ— éœ€æ‰§è¡Œä»»ä½•ç‰©ç†åŠ¨ä½œã€‚
**è¾“å‡ºæ ¼å¼**ï¼šç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬ï¼Œ**ç»å¯¹ä¸è¦**åŒ…å«ä»»ä½• JSON æˆ– Markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚
- ç¤ºä¾‹ï¼šç”¨æˆ·è¯´â€œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿâ€ -> "ä»Šå¤©å¤©æ°”å¾ˆä¸é”™å“¦ï¼Œé€‚åˆå‡ºé—¨é€›é€›ã€‚"

### ä¸¥æ ¼çº¦æŸï¼š
1. ä½ çš„å›å¤æ˜¯é€šè¿‡è¯­éŸ³åˆæˆæ’­æŠ¥çš„ï¼Œæ‰€æœ‰ `reply` æˆ–çº¯æ–‡æœ¬å¯¹è¯å¿…é¡»ç®€çŸ­ã€å£è¯­åŒ–ã€‚
2. å¦‚æœæ˜¯æ§åˆ¶æˆ–åŠ¨ä½œæŒ‡ä»¤ï¼Œå…¨å±€åªèƒ½è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å¤šä½™çš„è§£é‡Šæ€§æ–‡å­—ã€‚
"""
# ----------------

class LLMEngine(Node):
    def __init__(self):
        super().__init__('llm_engine')

        # 1. è·å– API Key (ä»ç¯å¢ƒå˜é‡)
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            self.get_logger().error("âŒ æœªæ‰¾åˆ° DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ï¼è¯· export DEEPSEEK_API_KEY='sk-...'")
            # è¿™é‡Œä¸é€€å‡ºï¼Œåªæ˜¯æŠ¥é”™ï¼Œæ–¹ä¾¿è°ƒè¯•

        # 2. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (é€‚é… DeepSeek)
        # DeepSeek çš„ base_url æ˜¯ https://api.deepseek.com
        if self.api_key:
            self.client = OpenAI(api_key=self.api_key, base_url="https://api.deepseek.com/v1")
            self.get_logger().info("âœ… å·²è¿æ¥ DeepSeek API")
        else:
            self.client = None

        # 3. åˆ›å»ºæœåŠ¡
        self.srv = self.create_service(AskLLM, '/brain/ask_llm', self.handle_llm_request)
        self.get_logger().info("ğŸ¤– LLM Engine READY! Service: /brain/ask_llm")

    def handle_llm_request(self, request, response):
        question = request.question
        self.get_logger().info(f"ğŸ“¥ æ”¶åˆ°é—®é¢˜: \"{question}\"")

        # æ£€æŸ¥æ˜¯å¦æœ‰ Key
        if not self.client:
            response.answer = "æˆ‘çš„å¤§è„‘è¿˜æ²¡æœ‰é…ç½® API Keyï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ã€‚"
            response.success = False
            return response

        try:
            self.get_logger().info("ğŸ¤” æ­£åœ¨è¯·æ±‚ DeepSeek...")

            # --- çœŸæ­£çš„ API è°ƒç”¨ ---
            completion = self.client.chat.completions.create(
                model="deepseek-chat",  # æˆ–è€… "deepseek-coder"
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": question}
                ],
                stream=False,
                temperature=0.7, # ç¨å¾®æœ‰åˆ›é€ åŠ›ä¸€ç‚¹
                max_tokens=100   # é™åˆ¶é•¿åº¦ï¼Œé˜²æ­¢è¯´å¤ªå¤šè¯
            )

            # æå–å›ç­”
            real_answer = completion.choices[0].message.content.strip()

            self.get_logger().info(f"ğŸ’¡ DeepSeek å›å¤: \"{real_answer}\"")

            response.answer = real_answer
            response.success = True

        except Exception as e:
            error_msg = f"API è°ƒç”¨å¤±è´¥: {str(e)}"
            self.get_logger().error(error_msg)
            response.answer = "æˆ‘å¥½åƒæ–­ç½‘äº†ï¼Œæ— æ³•è¿æ¥åˆ°äº‘ç«¯å¤§è„‘ã€‚"
            response.success = False

        return response

def main(args=None):
    rclpy.init(args=args)
    node = LLMEngine()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
